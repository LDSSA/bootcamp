{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU11 - Advanced Validation: Exercises notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Bias-variance trade-off\n",
    "\n",
    "### Exercise 1: Detecting bias and variance in a simple model (not graded)\n",
    "\n",
    "Imagine you are measuring voting intentions, namely the percentage of people that will vote in a given political party A, as opposed to political party B.\n",
    "\n",
    "A way to build this model would be to randomly choose 50 numbers from the phone book, call each one and ask the responder who they planned to vote.\n",
    "\n",
    "Now, consider we got the following results:\n",
    "\n",
    "| Party A | Party B | Non-Respondents | Total |\n",
    "|---------|---------|-----------------|-------|\n",
    "| 13      | 16      | 21              | 50    |\n",
    "\n",
    "From the data, we estimate the probability of voting A as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4482758620689655"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 / (13 + 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our (flawed, as we will see) model, we predict a victory for the party B. But can we expect our model to generalize, coming the elections?\n",
    "\n",
    "In order to understand that, we need to idenfify sources of bias and variance.\n",
    "\n",
    "Below you will find a list of issues undermining the model. You need to identify which ones are sources of bias and which ones are sources of variance:\n",
    "\n",
    "1. Only sampling people from the phone book (bias/~~variance~~)\n",
    "2. Not following-up with non-respondents (bias/variance)\n",
    "3. Not weighting responses by likeliness to vote (bias/variance)\n",
    "4. Small sample size (bias/variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict_1 = { 1 : 'bias',\n",
    "                   2 : 'bias',\n",
    "                   3 : 'bias',\n",
    "                   4 : 'variance' }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Detecting bias and variance in the real world (not graded)\n",
    "\n",
    "For each of the following, identify if they are more likely to be sources of bias or variance:\n",
    "\n",
    "1. Using very flexible models (e.g., non-parametric, non-linear), such as K-nearest neighbors or decision trees (bias/variance)\n",
    "2. Using models with simplistic assumptions, such as linear or logistic regressions (bias/variance)\n",
    "3. Increasing the polynomial degree of our hypothesis function (bias/variance)\n",
    "4. Ignoring important features (bias/variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_dict_2 = { 1 : 'variance', \n",
    "                   2 : 'bias',\n",
    "                   3 : 'variance',\n",
    "                   4 : 'bias'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train-test split\n",
    "\n",
    "### Exercise 3: Create training and test datasets (graded)\n",
    "\n",
    "1. Load the `data/beer.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer = pd.read_csv('data/beer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def implement_hold_out_method(X, y, test_size=.4):\n",
    "    \"\"\" \n",
    "    Implementing the holdout method, using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        test_size (float): proportion of the dataset to include in the test set\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): the features for the training examples\n",
    "        X_test (pd.DataFrame): the features for the test examples\n",
    "        y_train (pd.Series): target for the training set \n",
    "        y_test (pd.Series): target for the test set\n",
    "\n",
    "    \"\"\"\n",
    "    # use train_test_split to create the training and test datasets\n",
    "    # X_train, X_test, y_train, y_test = ...\n",
    "    ### BEGIN SOLUTION \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "from random import randint\n",
    "\n",
    "def generate_test_data(m , n):\n",
    "    values = np.random.randint(0, m, size=(m, n))\n",
    "    df = pd.DataFrame(values)\n",
    "    X = df.copy()\n",
    "    y = X.pop(0)\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_test_data(m=100, n=4)\n",
    "X_train, X_test, y_train, y_test = implement_hold_out_method(X, y)\n",
    "assert X_train.shape == (60, 3)\n",
    "assert X_test.shape == (40, 3)\n",
    "assert y_train.shape == (60, )\n",
    "assert y_test.shape == (40, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Creating a validation dataset (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_validation_dataset(X, y, test_size=.25, validation_size=.25):\n",
    "    \"\"\" \n",
    "    Implementing the holdout method with validation, using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        test_size (float): proportion of the dataset to include in the test set\n",
    "        validation_size (float): proportion of the dataset to include in the validation set\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): the features for the training examples\n",
    "        X_test (pd.DataFrame): the features for the test examples\n",
    "        y_train (pd.Series): target for the training set \n",
    "        y_test (pd.Series): target for the test set\n",
    "\n",
    "    \"\"\"\n",
    "    # use train_test_split to create the test dataset\n",
    "    # X_temp, X_test, y_temp, y_test = ...\n",
    "    ### BEGIN SOLUTION \n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    # compute the size of the validation dataset relative to the temp dataset\n",
    "    # validation_temp_size = ...\n",
    "    ### BEGIN SOLUTION \n",
    "    validation_temp_size = validation_size / (1 - test_size)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cross-validation\n",
    "\n",
    "### Exercise 5: Implementing K-fold cross-validation (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
