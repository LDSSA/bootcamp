{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU11 - Advanced Validation: Exercises notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Bias-variance trade-off\n",
    "\n",
    "### Exercise 1: Detecting bias and variance in a simple model (not graded)\n",
    "\n",
    "Imagine you are measuring voting intentions, namely the percentage of people that will vote in a given political party A, as opposed to political party B.\n",
    "\n",
    "A way to build this model would be to randomly choose 50 numbers from the phone book, call each one and ask the responder who they planned to vote.\n",
    "\n",
    "Now, consider we got the following results:\n",
    "\n",
    "| Party A | Party B | Non-Respondents | Total |\n",
    "|---------|---------|-----------------|-------|\n",
    "| 13      | 16      | 21              | 50    |\n",
    "\n",
    "From the data, we estimate the probability of voting A as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4482758620689655"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13 / (13 + 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our (flawed, as we will see) model, we predict a victory for the party B. But can we expect our model to generalize, coming the elections?\n",
    "\n",
    "In order to understand that, we need to idenfify sources of bias and variance.\n",
    "\n",
    "Below you will find a list of issues undermining the model. You need to identify which ones are sources of bias and which ones are sources of variance:\n",
    "\n",
    "1. Only sampling people from the phone book (bias/~~variance~~)\n",
    "2. Not following-up with non-respondents (bias/variance)\n",
    "3. Not weighting responses by likeliness to vote (bias/variance)\n",
    "4. Small sample size (bias/variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Detecting bias and variance in the real world (not graded)\n",
    "\n",
    "For each of the following, identify if they are more likely to be sources of bias or variance:\n",
    "\n",
    "1. Using very flexible models (e.g., non-parametric, non-linear), such as K-nearest neighbors or decision trees (bias/variance)\n",
    "2. Using models with simplistic assumptions, such as linear or logistic regressions (bias/variance)\n",
    "3. Increasing the polynomial degree of our hypothesis function (bias/variance)\n",
    "4. Ignoring important features (bias/variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Train-test split\n",
    "\n",
    "### Exercise 3: Create training and test datasets (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def implement_hold_out_method(X, y, test_size=.4, random_state=0):\n",
    "    \"\"\" \n",
    "    Implementing the holdout method, using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        test_size (float): proportion of the dataset to include in the test set\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): the features for the training examples\n",
    "        X_test (pd.DataFrame): the features for the test examples\n",
    "        y_train (pd.Series): target for the training set \n",
    "        y_test (pd.Series): target for the test set\n",
    "\n",
    "    \"\"\"\n",
    "    # use train_test_split to create the training and test datasets\n",
    "    # X_train, X_test, y_train, y_test = ...\n",
    "    ### BEGIN SOLUTION \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                        random_state=random_state)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "from random import randint\n",
    "\n",
    "def generate_test_data(m , n):\n",
    "    values = np.random.randint(0, m, size=(m, n))\n",
    "    df = pd.DataFrame(values)\n",
    "    X = df.copy()\n",
    "    y = X.pop(0)\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_test_data(m=100, n=4)\n",
    "X_train, X_test, y_train, y_test = implement_hold_out_method(X, y)\n",
    "assert X_train.shape == (60, 3)\n",
    "assert X_test.shape == (40, 3)\n",
    "assert y_train.shape == (60,)\n",
    "assert y_test.shape == (40,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Creating a validation dataset (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implement_validation_dataset(X, y, test_size=.25, validation_size=.25, random_state=0):\n",
    "    \"\"\" \n",
    "    Implementing the holdout method with validation, using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        test_size (float): proportion of the dataset to include in the test set\n",
    "        validation_size (float): proportion of the dataset to include in the validation set\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): the features for the training examples\n",
    "        X_test (pd.DataFrame): the features for the test examples\n",
    "        X_val ()\n",
    "        y_train (pd.Series): target for the training set \n",
    "        y_test (pd.Series): target for the test set\n",
    "\n",
    "    \"\"\"\n",
    "    # use train_test_split to create the test dataset\n",
    "    # X_temp, X_test, y_temp, y_test = ... (1 line)\n",
    "    ### BEGIN SOLUTION \n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                      random_state=random_state)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    # compute the size of the validation dataset relative to the temp dataset\n",
    "    # so that the final validation dataset corresponds to the validation_size\n",
    "    # validation_temp_size = ... (1 line)\n",
    "    ### BEGIN SOLUTION \n",
    "    validation_temp_size = validation_size / (1 - test_size)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    # se train_test_split to create the train and validation datasets\n",
    "    # X_train, X_val, y_train, y_val = ... (1 line)\n",
    "    ### BEGIN SOLUTION \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, \n",
    "                                                      test_size=validation_temp_size,\n",
    "                                                      random_state=random_state)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "from random import randint\n",
    "\n",
    "def generate_test_data(m , n):\n",
    "    values = np.random.randint(0, m, size=(m, n))\n",
    "    df = pd.DataFrame(values)\n",
    "    X = df.copy()\n",
    "    y = X.pop(0)\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_test_data(m=1000, n=5)\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = implement_validation_dataset(X, y)\n",
    "assert X_train.shape == (500, 4)\n",
    "assert X_test.shape == (250, 4)\n",
    "assert X_val.shape == (250, 4)\n",
    "assert y_train.shape == (500,)\n",
    "assert y_test.shape == (250,)\n",
    "assert y_val.shape == (250,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Cross-validation\n",
    "\n",
    "### Exercise 5: Implementing K-fold cross-validation (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def implement_cross_validation(X, y, n_splits, random_state=0):\n",
    "    \"\"\" \n",
    "    Implementing the cross-validation split, to create multiple train\n",
    "    and test set splits.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        n_folds (int): number of floats, must be at least 2\n",
    "\n",
    "    Returns:\n",
    "        folds (dict): dictionary containing the multiple train, test splits\n",
    "    \"\"\"\n",
    "    # initialize the KFold cross-validator from sklearn, using n_splits and\n",
    "    # random_sate\n",
    "    # kf = ... (1 line)\n",
    "    ### BEGIN SOLUTION\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state)\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    # initialize empty dictionary 'folds'\n",
    "    # folds = ... (1 line)\n",
    "    ### BEGIN SOLUTION\n",
    "    folds = {}\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # use train_index and test_index to create X_train, X_test, y_train,\n",
    "        # and y_test (for reference, check the sklearn documentation for kf,\n",
    "        # and remember that X and y are both dataframes)\n",
    "        # X_train, X_test = ...\n",
    "        # y_train, y_test = ...\n",
    "        ### BEGIN SOLUTION\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # create a 'fold' dictionary with keys 'X_train', 'X_test', 'y_train',\n",
    "        # and 'y_test' and use the respective datasets as values (please make\n",
    "        # sure you use the correct keys)\n",
    "        ### BEGIN SOLUTION\n",
    "        fold = {'X_train': X_train,\n",
    "                'X_test': X_test,\n",
    "                'y_train': y_train,\n",
    "                'y_test': y_test}\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # create a variable k (int) with the number of the fold (each of the\n",
    "        # iterations of the loop), to be used as key in the dict 'folds'\n",
    "        # k = ...\n",
    "        ### BEGIN SOLUTION\n",
    "        k = len(folds)\n",
    "        ### END SOLUTION\n",
    "        \n",
    "        # add the fold to the folds dictionary, using k as key and fold as \n",
    "        # value (hint: check dict.update())\n",
    "        ### BEGIN SOLUTION\n",
    "        folds.update({k: fold})\n",
    "        ### END SOLUTION\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "def generate_test_data(m , n):\n",
    "    values = np.random.randint(0, m, size=(m, n))\n",
    "    df = pd.DataFrame(values)\n",
    "    X = df.copy()\n",
    "    y = X.pop(0)\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_test_data(m=500, n=5)\n",
    "folds = implement_cross_validation(X, y, 5)\n",
    "assert len(folds) == 5\n",
    "for fold in folds.values():\n",
    "    assert fold['X_train'].shape == (400, 4)\n",
    "    assert fold['X_test'].shape == (100, 4)\n",
    "    assert fold['y_train'].shape == (400,)\n",
    "    assert fold['y_test'].shape == (100,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
