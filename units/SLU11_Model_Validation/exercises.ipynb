{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "142ec8a68aa5e785bb22f9b6bfbdef3a",
     "grade": false,
     "grade_id": "cell-05e844b835aa5580",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SLU11 - Advanced Validation: Exercises notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f2ea5b78ef6f66c7d1b38d9285aa2cb0",
     "grade": false,
     "grade_id": "cell-e42bb037a88a592b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ae9af53623e8465c2115f6a418e439ba",
     "grade": false,
     "grade_id": "cell-90cf0bd12ed05e21",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1 Bias-variance trade-off\n",
    "\n",
    "### Exercise 1: Detecting bias and variance in a simple model (not graded)\n",
    "\n",
    "Imagine you are measuring voting intentions, namely the percentage of people that will vote in a given political party A, as opposed to political party B.\n",
    "\n",
    "A way to build this model would be to randomly choose 50 numbers from the phone book, call each one and ask the responder who they planned to vote.\n",
    "\n",
    "Now, consider we got the following results:\n",
    "\n",
    "| Party A | Party B | Non-Respondents | Total |\n",
    "|---------|---------|-----------------|-------|\n",
    "| 13      | 16      | 21              | 50    |\n",
    "\n",
    "From the data, we estimate the probability of voting A as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2deda826a8f7a2fbcd9914412b084c05",
     "grade": false,
     "grade_id": "cell-5217b9fc496aa669",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "13 / (13 + 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8eca7e947d90399867b3c94ac25a31a0",
     "grade": false,
     "grade_id": "cell-2102e9daa24530a2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Using our (flawed, as we will see) model, we predict a victory for the party B. But can we expect our model to generalize, coming the elections?\n",
    "\n",
    "In order to understand that, we need to idenfify sources of bias and variance.\n",
    "\n",
    "Below you will find a list of issues undermining the model. You need to identify which ones are sources of bias and which ones are sources of variance:\n",
    "\n",
    "1. Only sampling people from the phone book (bias/~~variance~~)\n",
    "2. Not following-up with non-respondents (bias/variance)\n",
    "3. Not weighting responses by likeliness to vote (bias/variance)\n",
    "4. Small sample size (bias/variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0a8fa1407dad370c90e9feff83c57829",
     "grade": false,
     "grade_id": "cell-1f15b4c639c45f70",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2: Detecting bias and variance in the real world (not graded)\n",
    "\n",
    "For each of the following, identify if they are more likely to be sources of bias or variance:\n",
    "\n",
    "1. Using very flexible models (e.g., non-parametric, non-linear), such as K-nearest neighbors or decision trees (bias/variance)\n",
    "2. Using models with simplistic assumptions, such as linear or logistic regressions (bias/variance)\n",
    "3. Increasing the polynomial degree of our hypothesis function (bias/variance)\n",
    "4. Ignoring important features (bias/variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "22945f1e74e8a4fc916f19cadea790a7",
     "grade": false,
     "grade_id": "cell-58a365f406a228fe",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2 Train-test split\n",
    "\n",
    "### Exercise 3: Create training and test datasets (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "34b97fc95b6c3cca20a3a18739fdf981",
     "grade": false,
     "grade_id": "cell-34f35a43586a0e85",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def implement_hold_out_method(X, y, test_size=.4, random_state=0):\n",
    "    \"\"\" \n",
    "    Implementing the holdout method, using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        test_size (float): proportion of the dataset to include in the test set\n",
    "        random_state (int): the seed used by the random number generator\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): the features for the training examples\n",
    "        X_test (pd.DataFrame): the features for the test examples\n",
    "        y_train (pd.Series): target for the training set \n",
    "        y_test (pd.Series): target for the test set\n",
    "\n",
    "    \"\"\"\n",
    "    # use train_test_split to create the training and test datasets\n",
    "    # X_train, X_test, y_train, y_test = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c985b913b3b6e7e4e15197da2f33065e",
     "grade": true,
     "grade_id": "cell-d0784c116c6f5dda",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "from random import randint\n",
    "\n",
    "def generate_test_data(m , n):\n",
    "    values = np.random.randint(0, m, size=(m, n))\n",
    "    df = pd.DataFrame(values)\n",
    "    X = df.copy()\n",
    "    y = X.pop(0)\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_test_data(m=100, n=4)\n",
    "X_train, X_test, y_train, y_test = implement_hold_out_method(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cb2d27a125a36b36149bd63c961a9c96",
     "grade": false,
     "grade_id": "cell-af6e4ef9cfe15659",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 4: Creating a validation dataset (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "749a9ef6faac0a5d761ceda8b053cf52",
     "grade": false,
     "grade_id": "cell-8a287c4f6e7371cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def implement_validation_dataset(X, y, test_size=.25, val_size=.25, random_state=0):\n",
    "    \"\"\" \n",
    "    Implementing the holdout method with validation, using sklearn.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        test_size (float): proportion of the dataset to include in the test set\n",
    "        val_size (float): proportion of the dataset to include in the validation set\n",
    "        random_state (int): the seed used by the random number generator\n",
    "\n",
    "    Returns:\n",
    "        X_train (pd.DataFrame): the features for the training examples\n",
    "        X_test (pd.DataFrame): the features for the test examples\n",
    "        X_val (pd.DataFrame): the features of the validation examples\n",
    "        y_train (pd.Series): target for the training set \n",
    "        y_test (pd.Series): target for the test set\n",
    "        y_val (pd.Series): target for the validation set\n",
    "\n",
    "    \"\"\"\n",
    "    # use train_test_split to create the test dataset\n",
    "    # X_temp, X_test, y_temp, y_test = ... (1 line)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # compute the size of the validation dataset relative to the temp dataset\n",
    "    # so that the final validation dataset corresponds to the validation_size\n",
    "    # val_on_temp_size = ... (1 line)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # se train_test_split to create the train and validation datasets\n",
    "    # X_train, X_val, y_train, y_val = ... (1 line)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "aea2a7fa19cc83ef65b636ae22efa0be",
     "grade": true,
     "grade_id": "cell-4cd9ffbea2630f66",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "X, y = generate_test_data(m=1000, n=5)\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = implement_validation_dataset(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e117347fe671507c78b29eb08dbc0a4",
     "grade": false,
     "grade_id": "cell-970ade4434f10e80",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3 Cross-validation\n",
    "\n",
    "### Exercise 5: Implementing K-fold cross-validation (graded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "027f703f4a23ede22694888eac039907",
     "grade": false,
     "grade_id": "cell-d345ee872dc32ad0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def implement_cross_validation(X, y, n_splits, random_state=0):\n",
    "    \"\"\" \n",
    "    Implementing the cross-validation split, to create multiple train\n",
    "    and test set splits.\n",
    "    \n",
    "    Args:\n",
    "        X (pd.DataFrame): a pandas dataframe containing the features\n",
    "        y (pd.Series): a pandas series containing the target variable\n",
    "        n_folds (int): number of floats, must be at least 2\n",
    "        random_state (int): the seed used by the random number generator\n",
    "\n",
    "    Returns:\n",
    "        folds (dict): dictionary containing the multiple train, test splits\n",
    "    \"\"\"\n",
    "    # initialize the KFold cross-validator from sklearn, using n_splits and\n",
    "    # random_sate\n",
    "    # kf = ... (1 line)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # initialize empty dictionary 'folds'\n",
    "    # folds = ... (1 line)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # use train_index and test_index to create X_train, X_test, y_train,\n",
    "        # and y_test (for reference, check the sklearn documentation for kf,\n",
    "        # and remember that X and y are both dataframes)\n",
    "        # X_train, X_test = ...\n",
    "        # y_train, y_test = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # create a 'fold' dictionary with keys 'X_train', 'X_test', 'y_train',\n",
    "        # and 'y_test' and use the respective datasets as values (please make\n",
    "        # sure you use the correct keys)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # create a variable k (int) with the number of the fold (each of the\n",
    "        # iterations of the loop), to be used as key in the dict 'folds'\n",
    "        # k = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # add the fold to the folds dictionary, using k as key and fold as \n",
    "        # value (hint: check dict.update())\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b379fccba2a3bb350aaa20b853c23a23",
     "grade": true,
     "grade_id": "cell-3c4d6569fa14994f",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Check that the solution is correct.\"\"\"\n",
    "X, y = generate_test_data(m=500, n=5)\n",
    "folds = implement_cross_validation(X, y, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
