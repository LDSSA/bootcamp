{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a8d4275374630e07d71d0158ab5775b",
     "grade": false,
     "grade_id": "cell-79f2337e7779945a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SLU9 - Regression: Exercise notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "73314f66ca395b0f555f6253711a9d12",
     "grade": false,
     "grade_id": "cell-62ddf765d4352694",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this notebook you will practice the following:\n",
    "     - Simple Linear Regression\n",
    "     - Gradient Descent\n",
    "     - Multiple Linear Regression\n",
    "     - Using scikit learn linear regression implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "78f0f4f24276db999868305939c8832b",
     "grade": false,
     "grade_id": "cell-4cb0eb9c3a32286f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell creates the data and parameters that \n",
    "# you can use to test your implementations.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(59)\n",
    "\n",
    "data = pd.read_csv('data/boston (scaled).csv')\n",
    "\n",
    "x = data.drop('MEDV', axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "b0 = 1\n",
    "b1 = 1\n",
    "learning_rate = 0.3\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec1b96774a66d08facc4af501eb97d1e",
     "grade": false,
     "grade_id": "cell-74ff3f984bb74106",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1. Simple Linear Regression & Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "88d33e2ad4e926df65b93952deaeca49",
     "grade": false,
     "grade_id": "cell-a1eba3d354cdb022",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.1 Simple Linear Regression formula\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x$$\n",
    "\n",
    "where $\\hat{y}$ are the predictions, $\\beta_0$ is the intercept, $\\beta_1$ is the coefficient and $x$ is the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "80f88422ebe49b7880ecabc32f6d24cc",
     "grade": false,
     "grade_id": "cell-0658efc6a6964c6e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression(x, b0, b1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.Series with shape (num_observations, 1)\n",
    "            The input data to be used in y_hat.\n",
    "        b0 : float\n",
    "            The intercept in y_hat.\n",
    "        b1 : float\n",
    "            The coefficient in y_hat.\n",
    "    \n",
    "    Returns:\n",
    "        y_hat : numpy.array with shape\n",
    "            The prediction made by the simple linear regression.\n",
    "    \"\"\"\n",
    "    # y_hat = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7404327422a85f45be53a5a92be3cc45",
     "grade": false,
     "grade_id": "cell-0eef253a177e9b8f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "b0 = 1\n",
    "b1 = 1\n",
    "\n",
    "simple_linear_regression(x['INDUS'].head(10), b0, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "599278fd2d611f642efef55f548c4022",
     "grade": false,
     "grade_id": "cell-03602624cf2f6423",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "0   -0.287909\n",
    "1    0.406619\n",
    "2    0.406619\n",
    "3   -0.306878\n",
    "4   -0.306878\n",
    "5   -0.306878\n",
    "6    0.523346\n",
    "7    0.523346\n",
    "8    0.523346\n",
    "9    0.523346\n",
    "Name: INDUS, dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5716cdda8671c9a6e4088141ef8c4e06",
     "grade": true,
     "grade_id": "cell-651ae1ad52511300",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_array_almost_equal(\n",
    "    simple_linear_regression(np.arange(100, 110), -12, 30), \n",
    "    np.array([2988, 3018, 3048, 3078, 3108, 3138, 3168, 3198, 3228, 3258])\n",
    ")\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    simple_linear_regression(np.arange(100, 110), 0, 1), \n",
    "    np.array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])\n",
    ")\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    simple_linear_regression(np.arange(-10, 0), 0, -1.1), \n",
    "    np.array([11. ,  9.9,  8.8,  7.7,  6.6,  5.5,  4.4,  3.3,  2.2,  1.1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "28d7e8c19c9f8b4fcda1ca3de548215e",
     "grade": false,
     "grade_id": "cell-f92253d68d765109",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.2 Simple Linear Regression cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0059b7613c5ec3d942cb354bbf3e6dc7",
     "grade": false,
     "grade_id": "cell-4434455b8c4cde09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "$$J = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 = \\sum_{n=1}^N (y_n - (\\beta_0 + \\beta_1 x_n))^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fff9fc0e4427595f2a5cc1cfa344323a",
     "grade": false,
     "grade_id": "cell-d1049431fa099d4b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def linear_regression_cost_function(y, y_hat):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        y : pandas.Series\n",
    "            The targets.\n",
    "        y_hat : pandas.Series\n",
    "            The predictions made by linear regression.\n",
    "    \n",
    "    Returns:\n",
    "        cost : float\n",
    "    \"\"\"\n",
    "    # Perform the difference\n",
    "    # e = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Now, square the difference\n",
    "    # s = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Finally, take the mean.\n",
    "    # m = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "22a47ecfedf616d2f4a094e0283a2b21",
     "grade": false,
     "grade_id": "cell-e69f1ef19e032653",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "b0 = 1\n",
    "b1 = 1\n",
    "\n",
    "y_hat = simple_linear_regression(x['INDUS'], b0, b1)\n",
    "\n",
    "linear_regression_cost_function(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1287ce790b862791e996df0b1b23254",
     "grade": false,
     "grade_id": "cell-e7288f1226e8d058",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "557.9702490579907\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d356bdac9dc1e71395d164230d64089a",
     "grade": true,
     "grade_id": "cell-4510d1dc5df769f3",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "np.random.seed(109)\n",
    "\n",
    "a = np.random.rand(5)\n",
    "b = np.random.rand(5)\n",
    "\n",
    "assert math.isclose(\n",
    "    linear_regression_cost_function(a, b), \n",
    "    0.04809326223470955)\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "a = np.random.rand(5)\n",
    "b = np.random.rand(5)\n",
    "\n",
    "assert math.isclose(\n",
    "    linear_regression_cost_function(a, b), \n",
    "    0.13452136234584286)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "25159abe2176ea07691590e0011e333b",
     "grade": false,
     "grade_id": "cell-ca9113f8aa0a69bd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.3 Simple Linear Regression cost function partial derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1414135801f5f2fbb1aa32206bd80c76",
     "grade": false,
     "grade_id": "cell-75b5bbf760671c5f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "$$\\frac{\\partial J}{\\partial b_0} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n) $$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_1} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n)x_n $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "595089ebc08c65fc74ae3bffe077ef6a",
     "grade": false,
     "grade_id": "cell-ec9d739bbd2aea01",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression_partial_derivatives(x, y, b0, b1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.Series with shape (num_observations, 1)\n",
    "            The input data to be used in y_hat. \n",
    "        y : pandas.Series with shape (num_observations, 1)\n",
    "            The targets.\n",
    "        b0 : float\n",
    "            The intercept in y_hat.\n",
    "        b1 : float\n",
    "            The coefficient in y_hat.\n",
    "    \n",
    "    Returns:\n",
    "        dJ_db0 : float\n",
    "            Partial derivative of J in order to b0.\n",
    "        dJ_db1 : floats\n",
    "            Partial derivative of J in order to b1.\n",
    "    \"\"\"\n",
    "    # Get the predictions.\n",
    "    # y_hat = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Compute the difference between the targets and \n",
    "    # the predictions.\n",
    "    # y_dif = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Perform the mean as in the formula.\n",
    "    # dJ_db0 = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Same thing as 'dJ_db0' but this time you must \n",
    "    # account for the input 'x'.\n",
    "    # dJ_db1 = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return dJ_db0, dJ_db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d17be56605dc5b51fefd6348dfba5e0",
     "grade": false,
     "grade_id": "cell-844a78141384f42f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "b0 = 1\n",
    "b1 = 1\n",
    "\n",
    "simple_linear_regression_partial_derivatives(x['INDUS'], y, b0, b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2a5aa83466be7cc8479f5af483ead6d8",
     "grade": false,
     "grade_id": "cell-181a9a33d6216f33",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "(-43.065612648221354, 10.888944710164607)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0109c04e1467217a96ed8d62ea07563",
     "grade": true,
     "grade_id": "cell-9900d4d72d1a67b3",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "dJ_db0, dJ_db1 = simple_linear_regression_partial_derivatives(x['AGE'], y, b0, b1)\n",
    "assert math.isclose(dJ_db0, -43.065612648221354)\n",
    "assert math.isclose(dJ_db1, 8.92692579061515)\n",
    "\n",
    "dJ_db0, dJ_db1 = simple_linear_regression_partial_derivatives(x['INDUS'], y, b0, b1)\n",
    "assert math.isclose(dJ_db0, -43.065612648221354)\n",
    "assert math.isclose(dJ_db1, 10.888944710164607)\n",
    "\n",
    "dJ_db0, dJ_db1 = simple_linear_regression_partial_derivatives(x['TAX'], y, b0, b1)\n",
    "assert math.isclose(dJ_db0, -43.06561264822135)\n",
    "assert math.isclose(dJ_db1, 10.60982713399667)\n",
    "\n",
    "dJ_db0, dJ_db1 = simple_linear_regression_partial_derivatives(x['PTRATIO'], y, b0, b1)\n",
    "assert math.isclose(dJ_db0, -43.06561264822137)\n",
    "assert math.isclose(dJ_db1, 11.331099858515751)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d84432ac4e9e9a90018a0a092f04f0d",
     "grade": false,
     "grade_id": "cell-e3e6a01758287a36",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4 Adjusting Simple Linear Regression $\\beta_0$ and $\\beta_1$ parameters with batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8a343ff18cd8a75c82df6e121c5b839c",
     "grade": false,
     "grade_id": "cell-c832dde3abfc95c3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "1. _For epoch in 1...epochs:_\n",
    "    1. $\\beta_0 = \\beta_0 - \\alpha \\frac{\\partial J}{\\partial \\beta_0} = \\beta_0 + \\alpha \\frac{1}{N} \\sum_{n=1}^N 2 (y - \\hat{y})$ \n",
    "    2. _For i in 1..K:_\n",
    "        1. $\\beta_i = \\beta_i - \\alpha \\frac{\\partial J}{\\partial \\beta_i} = \\beta_i + \\alpha \\frac{1}{N} \\sum_{n=1}^N 2 (y - \\hat{y}) x_{i_n}$ \n",
    "        \n",
    "It might look too complicated when you look at it the first time. But if you use one of the functions that you already implemented in this notebook, you will only need to fill 3 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "59bc9e5dd1ca40e6ff2c58dada3b2926",
     "grade": false,
     "grade_id": "cell-f241c7ad9d6d1560",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression_batch_gradient_descent(x, y, b0, b1, learning_rate, epochs): \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.Series\n",
    "            The input features\n",
    "        y : pandas.Series\n",
    "            The target\n",
    "        b0 : float\n",
    "            The intercept\n",
    "        b1 : float\n",
    "            The coefficient\n",
    "        learning_rate : float\n",
    "            Learning rate\n",
    "        epochs : integer\n",
    "            Number of iterations to repeat the produce of \n",
    "            aggregation & adaptation of parameters.\n",
    "    \n",
    "    Returns:\n",
    "        b0 : float\n",
    "            The updated b0.\n",
    "        b1 : float\n",
    "            The updated b1.\n",
    "    \"\"\"\n",
    "    # For a number of epochs...\n",
    "    for epoch in range(epochs):\n",
    "        # Get the partial derivatives for b0 and b1.\n",
    "        # dJ_db0, dJ_db1 = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Update b0 using the gradient descent update rule.\n",
    "        # b0 = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Update b1 using the gradient descent update rule.\n",
    "        # b1 = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    return b0, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2b00395e31def4893ecec494b0816830",
     "grade": false,
     "grade_id": "cell-88d954f539a42e59",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "b0 = 1\n",
    "b1 = 1\n",
    "learning_rate = 0.3\n",
    "epochs = 100\n",
    "\n",
    "simple_linear_regression_batch_gradient_descent(x['INDUS'], y, \n",
    "                                                b0, b1, learning_rate, \n",
    "                                                epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "083e43701f268e8f5a883d268bfb674f",
     "grade": false,
     "grade_id": "cell-27b49e50d64f860e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "(22.532806324110656, -4.444472355082235)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dd9d9effdda430b803d9bbff64e22fdc",
     "grade": true,
     "grade_id": "cell-bde041d7d3d58681",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "b0, b1 = simple_linear_regression_batch_gradient_descent(x['AGE'], y, 1, 1, 0.1, 2)\n",
    "assert math.isclose(b0, 8.751810276679842)\n",
    "assert math.isclose(b1, -0.606846642310726)\n",
    "\n",
    "b0, b1 = simple_linear_regression_batch_gradient_descent(x['AGE'], y, 1, 1, 0.2, 2)\n",
    "assert math.isclose(b0, 14.78099604743083)\n",
    "assert math.isclose(b1, -1.8566162529968449)\n",
    "\n",
    "b0, b1 = simple_linear_regression_batch_gradient_descent(x['AGE'], y, 1, -2, 0.1, 10)\n",
    "assert math.isclose(b0, 20.220738850281734)\n",
    "assert math.isclose(b1, -3.3063247634511757)\n",
    "\n",
    "b0, b1 = simple_linear_regression_batch_gradient_descent(x['AGE'], y, 10, 1, 0.1, 100)\n",
    "assert math.isclose(b0, 22.53280632155769)\n",
    "assert math.isclose(b1, -3.4634628943983317)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "306f76d895aa54d3f45e2523df92e5f6",
     "grade": false,
     "grade_id": "cell-323f3707057d5783",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2. Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1332201581dea05406feec33874af9dc",
     "grade": false,
     "grade_id": "cell-f002e0f4e954380a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.1 Multiple Linear Regression formula\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\sum_{i=1}^K \\beta_i$$\n",
    "\n",
    "you won't need to implement this one since (1) you already have too many things to do in this notebook and (2) we used `numpy.dot` method to implement `multiple_linear_regression`. Sicne we have no learning units for numpy, this will serve as a small intro to numpy matrix operations. Also, you can use this function in the remaining exercises. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f59bb1aecee2f72045783f52417b1194",
     "grade": false,
     "grade_id": "cell-b8e92d44451b6f88",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def multiple_linear_regression(x, betas):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "            The input features.\n",
    "        betas : pandas.Series with shape (num_features + 1,)\n",
    "            The intercept is in betas[0].\n",
    "            The remaining indexes are for the coefficients.\n",
    "    \n",
    "    Returns:\n",
    "        y_hat : pandas.Series with shape (num_observations,)\n",
    "            The prediction made by the simple linear regression.\n",
    "    \"\"\"\n",
    "    # betas is a pandas.Series with shape (num_features+1,) \n",
    "    # and you need to have an numpy array with shape \n",
    "    # (num_features+1, 1). Use the numpy.reshape function \n",
    "    # to do that. Don't forget that you need to extract \n",
    "    # the numpy array from betas.\n",
    "    betas = betas.values.reshape((betas.shape[0], 1))\n",
    "    \n",
    "    # Extract the numpy array of x.\n",
    "    x = x.values\n",
    "    \n",
    "    # Perform the dot product between x and betas. \n",
    "    # Remember that the first index of betas contains \n",
    "    # the intercept.\n",
    "    dot_product = x.dot(betas[1:])\n",
    "    \n",
    "    # Sum between the intercept and \n",
    "    # the result of numpy dot product.\n",
    "    y_hat = betas[0] + dot_product\n",
    "    \n",
    "    # y_hat is, at this point, a numpy array with shape\n",
    "    # (num_observations,1) but we need to return a \n",
    "    # pandas Series. To do that, first, you need to turn \n",
    "    # y_hat into a numpy array with shape (num_observations,). \n",
    "    # Then, just create a pandas Series with it.\n",
    "    y_hat = y_hat[:, 0]\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a5d699471ab310fe81c20e737b4f2bf4",
     "grade": false,
     "grade_id": "cell-f9775e136d63c3f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(59)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "\n",
    "multiple_linear_regression(x, betas)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d634ae38fcef0d454f7b7b29e56e4055",
     "grade": false,
     "grade_id": "cell-0e54fd3a31f51054",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.2 Multiple Linear Regression partial derivatives\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_0} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n) $$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_1} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n)x_{1_n} $$\n",
    "\n",
    "$$...$$\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial b_K} = - \\frac{1}{N} \\sum_{n=1}^N 2(y_n - \\hat{y}_n)x_{K_n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f01bb1be4fc5ad4a8d1510bb8dc7deec",
     "grade": false,
     "grade_id": "cell-315f5fa32e6031cb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def multiple_linear_regression_partial_derivatives(x, y, betas):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "            \n",
    "        y : pandas.Series with shape (num_observations,)\n",
    "            \n",
    "        betas : pandas.Series with shape (num_features,)\n",
    "            \n",
    "    Returns:\n",
    "        dJ_dbetas : pandas.Series shape (num_features + 1,)\n",
    "            \n",
    "    \"\"\"\n",
    "    # Get the predictions.\n",
    "    # y_hat = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Compute the difference between the targets and \n",
    "    # the predictions.\n",
    "    # y_dif = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Initialize the numpy array of partial \n",
    "    # derivatives dJ_dbetas\n",
    "    dJ_dbetas = np.zeros((x.shape[1] + 1, 1))\n",
    "    \n",
    "    # Compute the partial derivative for b0.\n",
    "    # dJ_dbetas[0] = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Extract the partial derivatives of \n",
    "    # the remaining betas by iterating \n",
    "    # through x columns. Do not forget \n",
    "    # that you already computed the \n",
    "    # difference between y and y_hat.\n",
    "    for k, col in enumerate(x.columns): \n",
    "        # dJ_dbetas[k+1] = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    # Return dJ_dbetas as a pandas Series.\n",
    "    return pd.Series(dJ_dbetas[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f0b2891a318675145b1d092f968f052",
     "grade": false,
     "grade_id": "cell-17b1167c403e380b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(59)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "\n",
    "dJ_dbetas = multiple_linear_regression_partial_derivatives(x, y, betas)\n",
    "dJ_dbetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd9da7f67d8281684537a2dbc18c9e10",
     "grade": false,
     "grade_id": "cell-5edd760990993f43",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output: \n",
    "```\n",
    "0    -43.217542\n",
    "1      9.291666\n",
    "2     -6.925295\n",
    "3     11.225624\n",
    "4     -2.165538\n",
    "5     10.230802\n",
    "6    -13.486925\n",
    "7      9.110905\n",
    "8     -6.241895\n",
    "9     10.198382\n",
    "10    11.840369\n",
    "11    10.982597\n",
    "12    -7.077173\n",
    "13    15.731230\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "11c6b730da7bdde669579d0fd0ecb526",
     "grade": true,
     "grade_id": "cell-88a9aee18767d4b9",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "dJ_dbetas = multiple_linear_regression_partial_derivatives(x, y, betas)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    dJ_dbetas.values, \n",
    "    np.array([\n",
    "        -43.52297136,   9.84995035,  -8.61164594,  13.15861134,\n",
    "        -2.3471559 ,  11.61824741, -14.66608858,  10.66169585,\n",
    "        -7.75951691,  11.0529071 ,  13.01747345,  12.5651279 ,\n",
    "        -8.23394387,  17.23850363\n",
    "    ]))\n",
    "\n",
    "np.random.seed(31)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "dJ_dbetas = multiple_linear_regression_partial_derivatives(x, y, betas)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    dJ_dbetas.values, \n",
    "    np.array([\n",
    "        -44.493505  ,  10.06408594,  -6.90398047,  11.43074961,\n",
    "        -2.75243775,  10.03880847, -12.62970789,   8.75624782,\n",
    "        -6.36955005,  10.10041933,  11.68181673,  10.82887913,\n",
    "        -6.80454959,  15.29274361\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c54675911a616b73f2e4b4fd0a59d177",
     "grade": false,
     "grade_id": "cell-664e5ef6f8b4ed2e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 2.3 Adjusting Multiple Linear Regression $\\beta_i, 0 \\leq i \\leq K$  parameters with batch gradient descent\n",
    "\n",
    "It is almost the same thing as BGD for the simple linear regression. The difference is that we include all gradients within `dJ_dbetas` instead of having variable for each coefficient and intercept, as we had in `simple_linear_regression_batch_gradient_descent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d3ac10563f6f2eceeb3b3b3122b2ac50",
     "grade": false,
     "grade_id": "cell-3f64edb60cc15b1a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def multiple_linear_regression_batch_gradient_descent(x, y, betas, learning_rate, epochs): \n",
    "    # Let's create a copy of betas in order to avoid modifying \n",
    "    # the original pandas series.\n",
    "    betas = betas.copy()\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        # Get the partial derivatives of the cost function \n",
    "        # in relation to betas\n",
    "        # dJ_dbetas = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Change betas with the partial derivatives \n",
    "        # using the update rule.\n",
    "        # betas = ...\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f68fba831621a89ab05c69b2795f468",
     "grade": false,
     "grade_id": "cell-a3b2f928c7a3b0a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(59)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "multiple_linear_regression_batch_gradient_descent(x, y, betas, learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80a737e307fe90fca64f07eaefa122f0",
     "grade": false,
     "grade_id": "cell-9251131ceba84a3f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output:\n",
    "```\n",
    "0     22.532806\n",
    "1     -0.865834\n",
    "2      0.986377\n",
    "3     -0.091423\n",
    "4      0.715177\n",
    "5     -1.943218\n",
    "6      2.732713\n",
    "7     -0.026260\n",
    "8     -3.057927\n",
    "9      2.051976\n",
    "10    -1.417653\n",
    "11    -2.025991\n",
    "12     0.856775\n",
    "13    -3.720943\n",
    "dtype: float64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d3a646941f5e4f7584363d53d94cb25f",
     "grade": true,
     "grade_id": "cell-b26ec5b38f334783",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "learning_rate = 0.1\n",
    "epochs = 10\n",
    "\n",
    "betas_ = multiple_linear_regression_batch_gradient_descent(x, y, betas, learning_rate, epochs)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    betas_.values, \n",
    "    np.array([\n",
    "        20.16017926, -0.6730492 ,  0.6389492 , -0.39083784,  0.94646059,\n",
    "        -0.45076874,  3.38156555,  0.07365744, -1.11285391,  0.24015042,\n",
    "        -0.2833516 , -1.56644959,  0.88648266, -2.82315201]), \n",
    "    decimal=4)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(3812)\n",
    "betas = pd.Series(np.random.rand(x.shape[1] + 1))\n",
    "learning_rate = 0.1\n",
    "epochs = 1\n",
    "\n",
    "betas_ = multiple_linear_regression_batch_gradient_descent(x, y, betas, learning_rate, epochs)\n",
    "np.testing.assert_array_almost_equal(\n",
    "    betas_.values, \n",
    "    np.array([\n",
    "        4.59634601, -0.94864253,  1.74053584, -0.80294128,  0.5242436 ,\n",
    "        -0.4184868 ,  2.25130406, -0.14264096,  1.04598222, -0.76944881,\n",
    "        -0.85169055, -0.61287616,  0.90117628, -0.83743241]), \n",
    "    decimal=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0acf49ee9e9e3543c3e01751fafa9cd4",
     "grade": false,
     "grade_id": "cell-cf5c88836cf6ddb4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 3. Using scikit learn linear regression implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19180eb8d3fdb20c81c48dd0b1c7016c",
     "grade": false,
     "grade_id": "cell-937f830a0af4b428",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "497a932d57ecebd7fc1e4b29b3362859",
     "grade": false,
     "grade_id": "cell-4896df37a4f5670c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_sklearn_close_form_linear_regression_details(x, y):\n",
    "    \"\"\"\n",
    "    Fit a scikit linear regression using the closed \n",
    "    form method. Return coefficients (original and \n",
    "    normalized), intercept and R² score.\n",
    "    \n",
    "    Args: \n",
    "        x : pandas.DataFrame with shape (num_observations, num_features)\n",
    "        \n",
    "        y : pandas.Series with shape (num_observations)\n",
    "        \n",
    "    Return:\n",
    "        coefs : numpy array with shape (num_features,)\n",
    "        \n",
    "        normalized_coefs : numpy array with shape (num_features,)\n",
    "        \n",
    "        intercept : numpy array with shape (1,)\n",
    "        \n",
    "        score : float\n",
    "    \"\"\"\n",
    "    # Create the class instance.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Fit the regressor.\n",
    "    # lr...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Extract the coefficients and intercept.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Compute the R² score.\n",
    "    # score = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Normalize coefficients. \n",
    "    # Don't forget to INCLUDE THE SIGN \n",
    "    # of each coefficient.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return coefs, normalized_coefs, intercept, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4c1e7bf2a38f2d7a2e10e600b9aa7df6",
     "grade": false,
     "grade_id": "cell-a9aa187545d65c0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "coefs, normalized_coefs, intercept, score = get_sklearn_close_form_linear_regression_details(x, y)\n",
    "\n",
    "print('Feature coefficients: ')\n",
    "print(pd.Series(coefs, x.columns))\n",
    "print('\\n')\n",
    "\n",
    "print('Normalized feature coefficients: ')\n",
    "print(pd.Series(normalized_coefs, x.columns))\n",
    "print('\\n')\n",
    "\n",
    "print('Intercept: {}'.format(intercept))\n",
    "print('\\n')\n",
    "\n",
    "print('R² score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3516e2d48da0e7074ad10f991af5a87e",
     "grade": false,
     "grade_id": "cell-54e40cd72266dd66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Expected output: \n",
    "```\n",
    "Feature coefficients: \n",
    "CRIM      -0.920411\n",
    "ZN         1.080981\n",
    "INDUS      0.142967\n",
    "CHAS       0.682203\n",
    "NOX       -2.060092\n",
    "RM         2.670641\n",
    "AGE        0.021121\n",
    "DIS       -3.104448\n",
    "RAD        2.658787\n",
    "TAX       -2.075898\n",
    "PTRATIO   -2.062156\n",
    "B          0.856640\n",
    "LSTAT     -3.748680\n",
    "dtype: float64\n",
    "\n",
    "\n",
    "Normalized feature coefficients: \n",
    "CRIM      -0.041676\n",
    "ZN         0.048946\n",
    "INDUS      0.006473\n",
    "CHAS       0.030890\n",
    "NOX       -0.093280\n",
    "RM         0.120925\n",
    "AGE        0.000956\n",
    "DIS       -0.140568\n",
    "RAD        0.120389\n",
    "TAX       -0.093996\n",
    "PTRATIO   -0.093373\n",
    "B          0.038788\n",
    "LSTAT     -0.169739\n",
    "dtype: float64\n",
    "\n",
    "\n",
    "Intercept: 22.532806324110684\n",
    "\n",
    "\n",
    "R² score: 0.7406077428649427\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "544118bd877b53d2541bc919e88cdbd6",
     "grade": true,
     "grade_id": "cell-494d62919cc2de0c",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data_ = load_diabetes()\n",
    "\n",
    "x_ = pd.DataFrame(data_['data'])\n",
    "y_ = pd.Series(data_['target'])\n",
    "\n",
    "_c, _n, _i, _s = get_sklearn_close_form_linear_regression_details(x_, y_)\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    _c,\n",
    "    np.array([\n",
    "        -10.01219782, -239.81908937,  519.83978679,  324.39042769, \n",
    "        -792.18416163,  476.74583782,  101.04457032,  177.06417623, \n",
    "        751.27932109,   67.62538639]))\n",
    "\n",
    "np.testing.assert_array_almost_equal(\n",
    "    _n,\n",
    "    np.array([\n",
    "        -0.00289369, -0.06931178,  0.1502425 ,  0.09375432, -0.22895463,\n",
    "        0.13778762,  0.02920359,  0.05117454,  0.21713244,  0.01954488]))\n",
    "\n",
    "assert math.isclose(_i, 152.1334841628965)\n",
    "assert math.isclose(_s, 0.5177494254132934)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
