{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SLU10 - Classification: Exercise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook you will practice the following: \n",
    "\n",
    "    - What classification is for\n",
    "    - Logistic regression\n",
    "    - Cost function (concept)\n",
    "    - Binary classification\n",
    "    - Multiclass classification\n",
    "    - Sklearn logit\n",
    "    \n",
    "You thought that you would get away without implementing your own little Logistic Regression?\n",
    "\n",
    "<img src=\"https://memegenerator.net/img/instances/67671039/i-know-logistic-regression-show-me.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "# Exercise 1. Implement the Logistic Function\n",
    "*aka the sigmoid function*\n",
    "\n",
    "As a very simple warmup, you will implement the logistic function. Let's keep this simple!\n",
    "\n",
    "Here's a quick reminder of the formula:\n",
    "\n",
    "$$\\hat{p} = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "**Complete here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_function(z):\n",
    "    \"\"\" \n",
    "    Implementation of the logistic function by hand\n",
    "    \n",
    "    Args:\n",
    "        z (np.float64): a float\n",
    "\n",
    "    Returns:\n",
    "        proba (np.float64): the predicted probability for a given observation\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the numerator and the denominator and obtain the predicted probability \n",
    "    ### START CODE HERE ### (~3 lines)\n",
    "    numerator = None\n",
    "    denominator = None\n",
    "    proba = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def logistic_function(z):\n",
    "    \"\"\" \n",
    "    Implementation of the logistic function by hand\n",
    "    \n",
    "    Args:\n",
    "        z (np.float64): a float\n",
    "\n",
    "    Returns:\n",
    "        proba (np.float64): the predicted probability for a given observation\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # define the numerator and the denominator and obtain the predicted probability \n",
    "    ### START CODE HERE ### (~3 lines)\n",
    "    numerator = 1\n",
    "    denominator = 1 + np.exp(-z)\n",
    "    proba = numerator / denominator\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability: 0.77\n"
     ]
    }
   ],
   "source": [
    "z = 1.2\n",
    "print('Predicted probability: %.2f' % logistic_function(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "    Predicted probability: 0.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = 3.4\n",
    "assert np.isclose(np.round(logistic_function(z),2), 0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Make Predictions From Observations\n",
    "\n",
    "The next step is to implement a function that receives observations and returns predicted probabilities.\n",
    "\n",
    "For instance, remember that for an observation with two variables we have:\n",
    "\n",
    "$$z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2$$\n",
    "\n",
    "where $\\beta_0$ is the intercept and $\\beta_1, \\beta_2$ are the coefficients.\n",
    "\n",
    "**Complete here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_proba(x, coefficients):\n",
    "    \"\"\" \n",
    "    Implementation of a function that returns a predicted probability for a given data observation\n",
    "    \n",
    "    Args:\n",
    "        x (np.array): a numpy array of shape (n,)\n",
    "            - n: number of variables\n",
    "        coefficients (np.array): a numpy array of shape (n + 1,)\n",
    "            - coefficients[0]: intercept\n",
    "            - coefficients[1:]: remaining coefficients\n",
    "\n",
    "    Returns:\n",
    "        proba (np.array): the predicted probability for a given data observation\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # start by assigning the intercept to z \n",
    "    # clue: the intercept is the first element of the list of coefficients\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    z = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # sum the remaining variable * coefficient products to z\n",
    "    # clue: the variables and coefficients indeces are not exactly aligned, but correctly ordered\n",
    "    ### START CODE HERE ### (~2 lines)\n",
    "    for i in range(None):                     # iterate through the observation variables\n",
    "        z += None                             # multiply the variable value by its coefficient and add to proba\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # obtain the predicted probability from z\n",
    "    # clue: we already implemented something that can give us that\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    proba = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def predict_proba(x, coefficients):\n",
    "    \"\"\" \n",
    "    Implementation of a function that returns a predicted probability for a given data observation\n",
    "    \n",
    "    Args:\n",
    "        x (np.array): a numpy array of shape (n,)\n",
    "            - n: number of variables\n",
    "        coefficients (np.array): a numpy array of shape (n + 1,)\n",
    "            - coefficients[0]: intercept\n",
    "            - coefficients[1:]: remaining coefficients\n",
    "\n",
    "    Returns:\n",
    "        proba (np.array): the predicted probability for a given data observation\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # start by assigning the intercept to z \n",
    "    # clue: the intercept is the first element of the list of coefficients\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    z = coefficients[0]\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # sum the remaining variable * coefficient products to z\n",
    "    # clue: the variables and coefficients indeces are not exactly aligned, but correctly ordered\n",
    "    ### START CODE HERE ### (~2 lines)\n",
    "    for i in range(len(x)):                     # iterate through the observation variables\n",
    "        z += x[i] * coefficients[i+1]                             # multiply the variable value by its coefficient and add to proba\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # obtain the predicted probability from z\n",
    "    # clue: we already implemented something that can give us that\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    proba = logistic_function(z)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probability:  0.160\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.2,2.32,1.3,3.2])\n",
    "coefficients = np.array([2.1,0.22,-2, 0.4, 0.1])\n",
    "print('Predicted probability:  %.3f' % predict_proba(x, coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "    Predicted probability:  0.160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1,0,2,3.2])\n",
    "coefficients = np.array([-0.2,2,-6, 1.2, -1])\n",
    "assert np.isclose(np.round(predict_proba(x, coefficients),2), 0.73)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Compute the Cross-Entropy Cost Function\n",
    "\n",
    "As you will implement stochastic gradient descent, you only have to do the following for each prediction: \n",
    "\n",
    "$$H_{\\hat{p}}(y) =  - (y \\log(\\hat{p}) + (1-y) \\log (1-\\hat{p}))$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, proba):\n",
    "    \"\"\" \n",
    "    Implementation of a function that returns the Cross-Entropy loss\n",
    "    \n",
    "    Args:\n",
    "        y (np.int64): an integer\n",
    "        proba (np.float64): a float\n",
    "\n",
    "    Returns:\n",
    "        loss (np.float): a float with the resulting loss for a given prediction\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the inner left side of the loss function (for when y == 1)\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    left = None \n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # compute the inner right side of the loss function (for when y == 0)\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    right = None \n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "   \n",
    "    # compute the total loss\n",
    "    # clue: do not forget the minus sign\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    loss = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def cross_entropy(y, proba):\n",
    "    \"\"\" \n",
    "    Implementation of a function that returns the Cross-Entropy loss\n",
    "    \n",
    "    Args:\n",
    "        y (np.int64): an integer\n",
    "        proba (np.float64): a float\n",
    "\n",
    "    Returns:\n",
    "        loss (np.array): the resulting loss for a given prediction\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # compute the inner left side of the loss function (for when y == 1)\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    left = y * np.log(proba)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # compute the inner right side of the loss function (for when y == 0)\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    right = (1-y) * np.log(1-proba) \n",
    "    ### END CODE HERE ###\n",
    "   \n",
    "    # compute the total loss\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    loss = -1 * (left + right)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed loss:  0.357\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "proba = 0.7\n",
    "print('Computed loss:  %.3f' % cross_entropy(y, proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "    \n",
    "    Computed loss:  0.357"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = 1\n",
    "proba = 0.35\n",
    "assert np.isclose(np.round(cross_entropy(y, proba),3), 1.050)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Obtain the Optimized Coefficients \n",
    "Now that the warmup is done, let's do the most interesting exercise. Here you will implement the optimized coefficients through Stochastic Gradient Descent.\n",
    "\n",
    "Quick reminders:\n",
    "\n",
    "$$H_{\\hat{p}}(y) = - \\frac{1}{N}\\sum_{i=1}^{N} \\left [{ y_i \\ \\log(\\hat{p}_i) + (1-y_i) \\ \\log (1-\\hat{p}_i)} \\right ]$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\beta_{0(t+1)} = \\beta_{0(t)} - learning\\_rate \\frac{\\partial H_{\\hat{p}}(y)}{\\partial \\beta_{0(t)}}$$\n",
    "\n",
    "$$\\beta_{t+1} = \\beta_t - learning\\_rate \\frac{\\partial H_{\\hat{p}}(y)}{\\partial \\beta_t}$$\n",
    "\n",
    "which can be simplified to\n",
    "\n",
    "$$\\beta_{0(t+1)} = \\beta_{0(t)} + learning\\_rate \\left [(y - \\hat{p}) \\ \\hat{p} \\ (1 - \\hat{p})\\right]$$\n",
    "\n",
    "$$\\beta_{t+1} = \\beta_t + learning\\_rate \\left [(y - \\hat{p}) \\ \\hat{p} \\ (1 - \\hat{p}) \\ x \\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_coefficients(x_train, y_train, learning_rate, n_epoch):\n",
    "    \"\"\" \n",
    "    Implementation of a function that returns the optimized intercept and coefficients\n",
    "    \n",
    "    Args:\n",
    "        x_train (np.array): a numpy array of shape (m, n)\n",
    "            m: number of training observations\n",
    "            n: number of variables\n",
    "        y_train (np.array): a numpy array of shape (m,)\n",
    "        learning_rate (np.float64): a float\n",
    "        n_epoch (np.int64): an integer of the number of full training cycles to perform on the training set\n",
    "\n",
    "    Returns:\n",
    "        coefficients (np.array): a numpy array of shape (n+1,)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the coefficients array with zeros\n",
    "    # clue: use np.zeros()\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    coefficients = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # run the stochastic gradient descent algorithm n_epoch times and update the coefficients\n",
    "    ### START CODE HERE ### (~8 lines)\n",
    "    for epoch in range(None):               # iterate n_epoch times\n",
    "        loss = None                         # initialize the cross entropy loss\n",
    "        for x, y in zip(None, None):        # iterate through the training set observations and labels\n",
    "            proba = None                    # compute the predicted probability\n",
    "            loss += None                    # compute the cross entropy loss and add it\n",
    "            coefficients[0] += None          # update the intercept            \n",
    "            for i in range(None):           # iterate through the observation variables\n",
    "                coefficients[i + 1] += None  # update each coefficient\n",
    "        loss /= None                         # average the summed cross entropies\n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "        if(epoch%10):\n",
    "            print('>epoch=%d, learning_rate=%.3f, error=%.3f' % (epoch, l_rate, loss))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def compute_coefficients(x_train, y_train, learning_rate = 0.1, n_epoch = 50, verbose = False):\n",
    "    \"\"\" \n",
    "    Implementation of a function that returns the optimized intercept and coefficients\n",
    "    \n",
    "    Args:\n",
    "        x_train (np.array): a numpy array of shape (m, n)\n",
    "            m: number of training observations\n",
    "            n: number of variables\n",
    "        y_train (np.array): a numpy array of shape (m,)\n",
    "        learning_rate (np.float64): a float\n",
    "        n_epoch (np.int64): an integer of the number of full training cycles to perform on the training set\n",
    "        verbose (bool): whether to print the loss during the training\n",
    "\n",
    "    Returns:\n",
    "        coefficients (np.array): a numpy array of shape (n+1,)\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the coefficients array with zeros\n",
    "    # clue: use np.zeros()\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    coefficients = np.zeros(x_train.shape[1]+1)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # run the stochastic gradient descent algorithm n_epoch times and update the coefficients\n",
    "    ### START CODE HERE ### (~8 lines)\n",
    "    for epoch in range(n_epoch):            # iterate n_epoch times\n",
    "        loss = 0                            # initialize the cross entropy loss with zero\n",
    "        for (x, y) in zip(x_train, y_train):                   # iterate through the training set\n",
    "            proba = predict_proba(x, coefficients)                    # compute the predicted probability\n",
    "            loss += cross_entropy(y, proba)                    # compute the cross entropy loss and add it\n",
    "            coefficients[0] +=  learning_rate * (y-proba) * proba * (1-proba)          # update the intercept            \n",
    "            for i in range(len(x)):           # iterate through the observation variables\n",
    "                coefficients[i + 1] += learning_rate * (y-proba) * proba * (1-proba) * x[i]   # update each coefficient\n",
    "        loss /= x_train.shape[0]                         # average the summed cross entropies\n",
    "\n",
    "    ### END CODE HERE ### \n",
    "        if((epoch%10==0) & (verbose)):\n",
    "            print('epoch=%d, learning_rate=%.3f, error=%.3f' % (epoch, learning_rate, loss))\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, learning_rate=0.100, error=0.811\n",
      "epoch=10, learning_rate=0.100, error=0.675\n",
      "epoch=20, learning_rate=0.100, error=0.640\n",
      "epoch=30, learning_rate=0.100, error=0.606\n",
      "epoch=40, learning_rate=0.100, error=0.574\n",
      "Computed coefficients:\n",
      "[-0.82964483  0.02698239 -0.04632395  0.27761155]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.array([[1,2,3], [2,5,9], [3,1,4], [8,2,9]])\n",
    "y_train = np.array([0,1,0,1])\n",
    "learning_rate = 0.1\n",
    "n_epoch = 50\n",
    "coefficients = compute_coefficients(x_train, y_train, learning_rate=learning_rate, n_epoch=n_epoch, verbose=True)\n",
    "print('Computed coefficients:')\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "    \n",
    "    epoch=0, learning_rate=0.100, error=0.811\n",
    "    epoch=10, learning_rate=0.100, error=0.675\n",
    "    epoch=20, learning_rate=0.100, error=0.640\n",
    "    epoch=30, learning_rate=0.100, error=0.606\n",
    "    epoch=40, learning_rate=0.100, error=0.574\n",
    "    Computed coefficients:\n",
    "    [-0.82964483  0.02698239 -0.04632395  0.27761155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array([[3,1,3], [1,0,9], [3,3,4], [2,-1,10]])\n",
    "y_train = np.array([0,1,0,1])\n",
    "learning_rate = 0.3\n",
    "n_epoch = 100\n",
    "coefficients = compute_coefficients(x_train, y_train, learning_rate=learning_rate, n_epoch=n_epoch, verbose=False)\n",
    "assert np.allclose(coefficients, np.array([-0.25917811, -1.15128387, -0.85317139,  0.55286134]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Normalize Data\n",
    "\n",
    "Just a quick and easy function to normalize the data. It is crucial that your variables are adjusted between $[0;1]$ (normalized) or standardized so that you can correctly analyse some logistic regression coefficients for your possible future employer.\n",
    "\n",
    "You only have to implement this formula\n",
    "\n",
    "$$ x_{normalized} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    \"\"\" \n",
    "    Implementation of a function that normalizes your data variables\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): a numpy array of shape (m, n)\n",
    "            m: number of observations\n",
    "            n: number of variables\n",
    "\n",
    "    Returns:\n",
    "        normalized_data (np.array): a numpy array of shape (m, n)\n",
    "\n",
    "    \"\"\"\n",
    "    # compute the numerator\n",
    "    # clue: use np.min()\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    numerator = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # compute the numerator\n",
    "    # clue: use np.max() and np.min()\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    denominator = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # obtain the normalized data\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    normalized_data = None\n",
    "    ### END CODE HERE ###\n",
    "    raise NotImplementedError()  \n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def normalize_data(data):\n",
    "    \"\"\" \n",
    "    Implementation of a function that normalizes your data variables\n",
    "    \n",
    "    Args:\n",
    "        data (np.array): a numpy array of shape (m, n)\n",
    "            m: number of observations\n",
    "            n: number of variables\n",
    "\n",
    "    Returns:\n",
    "        normalized_data (np.array): a numpy array of shape (m, n)\n",
    "\n",
    "    \"\"\"\n",
    "    # compute the numerator\n",
    "    # clue: use np.min()\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    numerator = data - np.min(data,axis=0)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # compute the numerator\n",
    "    # clue: use np.max() and np.min()\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    denominator = np.max(data,axis=0) - np.min(data,axis=0)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # obtain the normalized data\n",
    "    ### START CODE HERE ### (~1 line)\n",
    "    normalized_data = numerator / denominator\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization:\n",
      "[[ 9  5  2]\n",
      " [ 7  7  3]\n",
      " [ 2  2 11]\n",
      " [ 1  5  2]\n",
      " [10  1  3]\n",
      " [ 0  9  5]]\n",
      "\n",
      "-------------------\n",
      "\n",
      "After normalization:\n",
      "[[0.9        0.5        0.        ]\n",
      " [0.7        0.75       0.11111111]\n",
      " [0.2        0.125      1.        ]\n",
      " [0.1        0.5        0.        ]\n",
      " [1.         0.         0.11111111]\n",
      " [0.         1.         0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[9,5,2], [7,7,3], [2,2,11], [1,5,2], [10,1,3], [0,9,5]])\n",
    "normalized_data = normalize_data(data)\n",
    "print('Before normalization:')\n",
    "print(data)\n",
    "print('\\n-------------------\\n')\n",
    "print('After normalization:')\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "    \n",
    "    Before normalization:\n",
    "    [[ 9  5  2]\n",
    "     [ 7  7  3]\n",
    "     [ 2  2 11]\n",
    "     [ 1  5  2]\n",
    "     [10  1  3]\n",
    "     [ 0  9  5]]\n",
    "\n",
    "    -------------------\n",
    "\n",
    "    After normalization:\n",
    "    [[0.9        0.5        0.        ]\n",
    "     [0.7        0.75       0.11111111]\n",
    "     [0.2        0.125      1.        ]\n",
    "     [0.1        0.5        0.        ]\n",
    "     [1.         0.         0.11111111]\n",
    "     [0.         1.         0.33333333]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array([[9,5,2,6], [7,5,1,3], [2,2,11,1]])\n",
    "normalized_data = normalize_data(data)\n",
    "assert np.allclose(normalized_data, np.array([[1., 1., 0.1, 1.],[0.71428571, 1., 0., 0.4],[0., 0., 1., 0.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Putting it All Together\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wisconsin Breast Cancer Diagnostic dataset is another data science classic. It is the result of extraction of breast cell's nuclei characteristics to understand which of them are the most relevent for developing breast cancer.\n",
    "\n",
    "Your quest, is to first analyze this dataset from the materials that you've learned in the previous SLUs and then create a logistic regression model that can correctly classify cancer cells from healthy ones.\n",
    "\n",
    "Dataset description:\n",
    "\n",
    "    1. Sample code number: id number \n",
    "    2. Clump Thickness\n",
    "    3. Uniformity of Cell Size\n",
    "    4. Uniformity of Cell Shape\n",
    "    5. Marginal Adhesion \n",
    "    6. Single Epithelial Cell Size\n",
    "    7. Bare Nuclei\n",
    "    8. Bland Chromatin\n",
    "    9. Normal Nucleoli\n",
    "    10. Mitoses \n",
    "    11. Class: (2 for benign, 4 for malignant) > We will modify to (0 for benign, 1 for malignant) for simplicity\n",
    "    \n",
    "The data is loaded for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['Sample code number','Clump Thickness','Uniformity of Cell Size','Uniformity of Cell Shape',\n",
    "           'Marginal Adhesion','Single Epithelial Cell Size','Bare Nuclei','Bland Chromatin','Normal Nucleoli',\n",
    "           'Mitoses','Class']\n",
    "data = pd.read_csv('data/breast-cancer-wisconsin.csv',names=columns, index_col=0)\n",
    "data[\"Bare Nuclei\"] = data[\"Bare Nuclei\"].replace(['?'],np.nan)\n",
    "data = data.dropna()\n",
    "data[\"Bare Nuclei\"] = data[\"Bare Nuclei\"].map(int)\n",
    "data.Class = data.Class.map(lambda x: 1 if x == 4 else 0)\n",
    "X = data.drop('Class').values\n",
    "y_train = data.Class.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And use these values for your logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "n_epoch = 100\n",
    "\n",
    "# For validation\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're on your own!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-b215a9119196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Explore the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# How many patients have breast cancer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_cancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients have breast cancer?\n",
    "n_cancer = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients are healthy?\n",
    "n_healthy = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Normalize the training data X\n",
    "x_train = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# What coefficients can we get?\n",
    "coefficients = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Initialize the predicted probabilities list\n",
    "probas = None\n",
    "\n",
    "# What are the predicted probabilities on the training data?\n",
    "for x in None:\n",
    "    probas.append(None)\n",
    "raise NotImplementedError()\n",
    "\n",
    "# If we had to say whether a patient had breast cancer, what are the predictions?\n",
    "# clue 1: Hard assign the predicted probabilities by rounding them to the nearest integer\n",
    "# clue 2: use np.round()\n",
    "preds = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients were predicted to have breast cancer?\n",
    "n_predicted_cancer = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients with cancer were correctly detected?\n",
    "n_correct_cancer_predictions = None\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, learning_rate=0.010, error=0.617\n",
      "epoch=10, learning_rate=0.010, error=0.209\n",
      "epoch=20, learning_rate=0.010, error=0.143\n",
      "epoch=30, learning_rate=0.010, error=0.114\n",
      "epoch=40, learning_rate=0.010, error=0.097\n",
      "epoch=50, learning_rate=0.010, error=0.086\n",
      "epoch=60, learning_rate=0.010, error=0.077\n",
      "epoch=70, learning_rate=0.010, error=0.071\n",
      "epoch=80, learning_rate=0.010, error=0.066\n",
      "epoch=90, learning_rate=0.010, error=0.062\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "# Explore the dataset\n",
    "\n",
    "# How many patients have breast cancer?\n",
    "n_cancer = y_train[y_train==1].shape[0]\n",
    "\n",
    "# How many patients are healthy?\n",
    "n_healthy = y_train[y_train==0].shape[0]\n",
    "\n",
    "# Normalize the training data X\n",
    "x_train = normalize_data(X)\n",
    "\n",
    "# What coefficients can we get?\n",
    "coefficients = compute_coefficients(x_train, y_train, learning_rate=learning_rate, n_epoch=n_epoch, verbose=True)\n",
    "\n",
    "# Initialize the predicted probabilities list\n",
    "probas = []\n",
    "\n",
    "# What are the predicted probabilities on the training data?\n",
    "for x in x_train:\n",
    "    probas.append(predict_proba(x, coefficients=coefficients))\n",
    "\n",
    "# If we had to say whether a patient had breast cancer, what are the predictions?\n",
    "# clue 1: Hard assign the predicted probabilities by rounding them to the nearest integer\n",
    "# clue 2: use np.round()\n",
    "preds = np.round(probas)\n",
    "\n",
    "# How many patients were predicted to have breast cancer?\n",
    "n_predicted_cancer = preds[preds==1].shape[0]\n",
    "\n",
    "# How many patients with cancer were correctly detected?\n",
    "n_correct_cancer_predictions = y_train[preds==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have a dataset with 239 cells with cancer and 444 healthy cells. \n",
      "\n",
      "After analysing the data and training your own logistic regression classifier you find out that it correctly identified 239 out of 239 cancer cells which were all of them. You feel very lucky and happy. However, shortly after you get somewhat suspicious after getting such amazing results. You feel that they should not be that good, but you do not know how to be sure of it. You say to yourself that you will definitely be present when doing the next Small Learning Unit 11, which will tackle exactly that.\n"
     ]
    }
   ],
   "source": [
    "print('You have a dataset with %s cells with cancer and %s healthy cells. \\n\\n'\n",
    "     'After analysing the data and training your own logistic regression classifier you find out that it correctly '\n",
    "     'identified %s out of %s cancer cells which were all of them. You feel very lucky and happy. However, shortly '\n",
    "     'after you get somewhat suspicious after getting such amazing results. You feel that they should not be '\n",
    "     'that good, but you do not know how to be sure of it. You say to yourself that you will definitely be '\n",
    "     'present when doing the next Small Learning Unit 11, which will tackle exactly that.' % \n",
    "      (n_cancer, n_healthy, n_predicted_cancer, n_correct_cancer_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Test output (don't change code here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Using the Sklearn's SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final exercise, you will do exactly what you did in the previous one, but now by using the sklearn's Logistic Regression implementation.\n",
    "\n",
    "Let's just define the hyperparameters first, be sure to use them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "learning_rate_schedule = \"constant\"\n",
    "n_epoch = 100\n",
    "loss = \"log\"\n",
    "random_state = 0\n",
    "penalty = None\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-126-09a22b5f044b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# How many patients have breast cancer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn_cancer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# How many patients are healthy?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# How many patients have breast cancer?\n",
    "n_cancer = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients are healthy?\n",
    "n_healthy = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Normalize the training data X\n",
    "x_train = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create the sklearn's SGDClassifier object with the training data\n",
    "clf = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Fit the classifier with the training data\n",
    "\n",
    "raise NotImplementedError()\n",
    "\n",
    "# What coefficients can we get?\n",
    "coefficients = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# What are the predicted probabilities on the training data?\n",
    "probas = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# If we had to say whether a patient had breast cancer, what are the predictions?\n",
    "# Suggestion: This time, try to do the same but with a logistic regression method\n",
    "preds = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients were predicted to have breast cancer?\n",
    "n_predicted_cancer = None\n",
    "raise NotImplementedError()\n",
    "\n",
    "# How many patients with cancer were correctly detected?\n",
    "n_correct_cancer_predictions = None\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "# How many patients have breast cancer?\n",
    "n_cancer = y_train[y_train==1].shape[0]\n",
    "\n",
    "# How many patients are healthy?\n",
    "n_healthy = y_train[y_train==0].shape[0]\n",
    "\n",
    "# Normalize the training data X\n",
    "x_train = normalize_data(X)\n",
    "\n",
    "# Create the sklearn's SGDClassifier object with the training data\n",
    "clf = SGDClassifier(random_state=random_state,\n",
    "                    loss=loss,\n",
    "                    penalty=penalty,\n",
    "                    shuffle=shuffle,\n",
    "                    learning_rate=learning_rate_schedule,\n",
    "                    eta0=learning_rate,\n",
    "                    max_iter=n_epoch)\n",
    "\n",
    "# Fit the classifier with the training data\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# What coefficients can we get?\n",
    "coefficients = clf.coef_\n",
    "\n",
    "# What are the predicted probabilities on the training data?\n",
    "probas = clf.predict_proba(x_train)\n",
    "\n",
    "# If we had to say whether a patient had breast cancer, what are the predictions?\n",
    "# Suggestion: This time, try to do the same but with a logistic regression method\n",
    "preds = clf.predict(x_train)\n",
    "\n",
    "# How many patients were predicted to have breast cancer?\n",
    "n_predicted_cancer = preds[preds==1].shape[0]\n",
    "\n",
    "# How many patients with cancer were correctly detected?\n",
    "n_correct_cancer_predictions = y_train[preds==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have a dataset with 239 cells with cancer and 444 healthy cells. \n",
      "\n",
      "After analysing the data and training the sklearn's SGDClassifier you find out that it correctly identified 239 out of 239 cancer cells which were all of them. You feel very lucky and happy. However, shortly after you get somewhat suspicious after getting such amazing results. You feel that they should not be that good, but you do not know how to be sure of it. You say to yourself that you will definitely be present when doing the next Small Learning Unit 11, which will tackle exactly that.\n"
     ]
    }
   ],
   "source": [
    "print('You have a dataset with %s cells with cancer and %s healthy cells. \\n\\n'\n",
    "     'After analysing the data and training the sklearn\\'s SGDClassifier you find out that it correctly '\n",
    "     'identified %s out of %s cancer cells which were all of them. You feel very lucky and happy. However, shortly '\n",
    "     'after you get somewhat suspicious after getting such amazing results. You feel that they should not be '\n",
    "     'that good, but you do not know how to be sure of it. You say to yourself that you will definitely be '\n",
    "     'present when doing the next Small Learning Unit 11, which will tackle exactly that.' % \n",
    "      (n_cancer, n_healthy, n_predicted_cancer, n_correct_cancer_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test output (don't change code here)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
