{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Mean Absolute Error (MAE)]()\n",
    "* [Mean Squared Error (MSE)]()\n",
    "* [Root Mean Squared Error (RMSE)]()\n",
    "* [Coefficient of Determination (R²)]()\n",
    "* [Adjusted R²]()\n",
    "* [Regularization]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.random.rand(20, 1)\n",
    "y2 = np.random.rand(20, 1)\n",
    "betas = np.random.rand(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34624114035876674"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34624114035876674"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1745076219474495"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1745076219474495"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y1, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599885346815766"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularized_linear_regression_cost_to_be_optimized(y1, y2, betas, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y, y_hat): \n",
    "    return np.abs(y - y_hat).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_hat):\n",
    "    return ((y - y_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_hat):\n",
    "    return mse.sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of Determination (R²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y, y_hat):\n",
    "    # TODO\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r_squared(y, y_hat, N, K):\n",
    "    (N - K - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "* https://www.r-bloggers.com/assessing-the-accuracy-of-our-models-r-squared-adjusted-r-squared-rmse-mae-aic/\n",
    "* https://pt.coursera.org/learn/competitive-data-science/lecture/UWhYf/regression-metrics-review-i\n",
    "\n",
    "\n",
    "MSE vs RMSE\n",
    "\n",
    "> Derivada do RMSE em relação a y_hat é igual ao gradiente do MSE a multiplicar por 1/(2 * sqrt(MSE)).\n",
    "\n",
    "\n",
    "RMSE: \n",
    "\n",
    "> The RMSE has the same measuring unit of the variable y.\n",
    "\n",
    "\n",
    "Problems with MSE and RMSE:\n",
    "> If our model explains the large majority of the variation in the data very well, with few exceptions; these exceptions will inflate the value of RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 + \\lambda_1 \\|\\beta\\|_1^1+  \\lambda_2 \\| \\beta \\|_2^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_linear_regression_cost_to_be_optimized(y, y_hat, betas, l1_lamb, l2_lamb): \n",
    "    return ((y - y_hat)**2).mean() + l1_lamb * (betas**2).sum() + l2_lamb * np.abs(betas).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularized_linear_regression_partial_derivative(y, y_hat, betas, l1_lamb, l2_lamb):\n",
    "    # TODO\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new version of the linear regression, you can implement 3 additional well known linear models:\n",
    "* ridge regression: $\\lambda_1 = 0$ and $\\lambda_2 > 0$ \n",
    "* lasso regression: $\\lambda_1 > 1$ and $\\lambda_2 = 0$ \n",
    "* elastic net regression: having both $\\lambda_1$ and $\\lambda_2$ TODO. If you want to normalize TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
